{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set size\n",
    "For this lab I used tha same data set that I produced in Lab 6, since it consists of 5000 observations (compared to example's 1000 observations), which has proven to impove accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dict1.csv\", header = None, names = [\"Angles\", \"XY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angles</th>\n",
       "      <th>XY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.40510000000000002, -0.097100000000000006, ...</td>\n",
       "      <td>[ 3.5048  0.9169  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-0.19320000000000001, 0.1341, -0.264699999999...</td>\n",
       "      <td>[ 3.6347  0.3976  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.192, 0.155, -0.28570000000000001, -0.393199...</td>\n",
       "      <td>[ 3.1567 -1.6357  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.24679999999999999, -0.18140000000000001, 0....</td>\n",
       "      <td>[ 3.2989 -1.5492  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-0.35449999999999998, 0.3926, 0.1613, 0.07829...</td>\n",
       "      <td>[ 3.6155 -0.2022  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.31819999999999998, -0.22770000000000001, -0...</td>\n",
       "      <td>[ 3.6511 -0.3356  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.4531, 0.085400000000000004, 0.4546, 0.09879...</td>\n",
       "      <td>[ 3.4324  0.4782  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.1404, -0.065500000000000003, -0.08409999999...</td>\n",
       "      <td>[ 3.6861  0.241   0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.34379999999999999, 0.27279999999999999, -0....</td>\n",
       "      <td>[ 3.1972 -1.6062  0.25  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.21460000000000001, -0.1293, -0.040399999999...</td>\n",
       "      <td>[ 3.6256  0.3925  0.25  ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Angles  \\\n",
       "0  (-0.40510000000000002, -0.097100000000000006, ...   \n",
       "1  (-0.19320000000000001, 0.1341, -0.264699999999...   \n",
       "2  (0.192, 0.155, -0.28570000000000001, -0.393199...   \n",
       "3  (0.24679999999999999, -0.18140000000000001, 0....   \n",
       "4  (-0.35449999999999998, 0.3926, 0.1613, 0.07829...   \n",
       "5  (0.31819999999999998, -0.22770000000000001, -0...   \n",
       "6  (0.4531, 0.085400000000000004, 0.4546, 0.09879...   \n",
       "7  (0.1404, -0.065500000000000003, -0.08409999999...   \n",
       "8  (0.34379999999999999, 0.27279999999999999, -0....   \n",
       "9  (0.21460000000000001, -0.1293, -0.040399999999...   \n",
       "\n",
       "                          XY  \n",
       "0  [ 3.5048  0.9169  0.25  ]  \n",
       "1  [ 3.6347  0.3976  0.25  ]  \n",
       "2  [ 3.1567 -1.6357  0.25  ]  \n",
       "3  [ 3.2989 -1.5492  0.25  ]  \n",
       "4  [ 3.6155 -0.2022  0.25  ]  \n",
       "5  [ 3.6511 -0.3356  0.25  ]  \n",
       "6  [ 3.4324  0.4782  0.25  ]  \n",
       "7  [ 3.6861  0.241   0.25  ]  \n",
       "8  [ 3.1972 -1.6062  0.25  ]  \n",
       "9  [ 3.6256  0.3925  0.25  ]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Angles'].to_numpy()\n",
    "train = data['XY'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "for i in range(len(train)):\n",
    "    train[i] = train[i].replace('   ', ' ')\n",
    "    train[i] = train[i].replace('  ', ' ')\n",
    "    train[i] = train[i].strip('[ ').strip(' ]')\n",
    "    labels[i] = labels[i].strip('(').strip(')')\n",
    "    result = [float(val) for val in labels[i].split(',')]\n",
    "    Y.append(result)\n",
    "    result = [float(val) for val in train[i].split(' ')]\n",
    "    X.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "(1000, 5)\n",
      "(4001, 3)\n",
      "(4001, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function, layers and optimizer\n",
    "In this lab I just used the most effective loss function from the Lab 6 (tested among MSLE, MAE, MSE and Regular RMSE). Besides, I addded one more hidden layer and used Adam optimizer, also based on the result obtained in Lab 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.01806\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = 3, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Adam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.80)\n",
    "model.fit(X_train, y_train, epochs = 10, verbose = 0)\n",
    "scores_msle = model.evaluate(X_test, y_test, verbose=0) \n",
    "print(\"RMSE: %.5f\" % (scores_msle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 573\n",
      "Trainable params: 573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0182\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.0183\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 0s 179us/step - loss: 0.0183\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0183\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 0s 145us/step - loss: 0.0183\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 0.0183\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 0s 161us/step - loss: 0.0183\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 0s 150us/step - loss: 0.0183\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 0.0182\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 0s 134us/step - loss: 0.0183\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 0.0183\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 0s 146us/step - loss: 0.0183\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 0.0182\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 0.0183\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 0s 119us/step - loss: 0.0184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad284df110>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.018\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0) \n",
    "print(\"RMSE: %.3f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1716738   0.22191347  0.19492155 -0.2310429   0.3181228 ]]\n",
      "[0.2537 0.0664 0.0664 0.1766 0.4265]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train[10].reshape(1,3)))\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Performance:\n",
    "### Old RMSE = 0.1 |     New RMSE = 0.018\n",
    "### Used properties: \n",
    "Data-set of 5000 observations <br>\n",
    "Loss function: MSLE - Mean Squared Logarithmic Error<br>\n",
    "Number of layers: 4 <br>\n",
    "Number of epochs: 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
